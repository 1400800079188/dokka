{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dokka \u00b6 Dokka is an API documentation engine for Kotlin. If you want to learn how to use Dokka, see documentation on kotlinlang.org . If you want to learn more about Dokka's internals and/or how to write Dokka plugins, see Developer guides .","title":"Dokka"},{"location":"#dokka","text":"Dokka is an API documentation engine for Kotlin. If you want to learn how to use Dokka, see documentation on kotlinlang.org . If you want to learn more about Dokka's internals and/or how to write Dokka plugins, see Developer guides .","title":"Dokka"},{"location":"community/slack/","text":"Slack channel \u00b6 Dokka has a dedicated #dokka channel in the Kotlin Community Slack , where you can ask questions and chat about using, customizing or contributing to Dokka . Follow the instructions to get an invite or connect directly .","title":"Slack"},{"location":"community/slack/#slack-channel","text":"Dokka has a dedicated #dokka channel in the Kotlin Community Slack , where you can ask questions and chat about using, customizing or contributing to Dokka . Follow the instructions to get an invite or connect directly .","title":"Slack channel"},{"location":"developer_guide/introduction/","text":"Developer guides \u00b6 The purpose of Developer guides section is to get you acquainted with Dokka's internals so that you can start developing your own plugins or contributing features and fixes to Dokka itself. If you want to start hacking on Dokka right away, the only thing you need to be aware of is the general workflow , it will teach you how to build, debug and test Dokka locally. If you want to get into plugin development quick, see Introduction to plugin development . If you have time to spare and want to know more about Dokka's internals, its architecture and capabilities, follow Architecture overview and subsequent sections inside Internals . Having read through all the developer guides, you'll have a pretty good unrestanding of Dokka and how to develop for it. If you have any questions, feel free to get in touch with maintainers via Slack or GitHub .","title":"Developer guides"},{"location":"developer_guide/introduction/#developer-guides","text":"The purpose of Developer guides section is to get you acquainted with Dokka's internals so that you can start developing your own plugins or contributing features and fixes to Dokka itself. If you want to start hacking on Dokka right away, the only thing you need to be aware of is the general workflow , it will teach you how to build, debug and test Dokka locally. If you want to get into plugin development quick, see Introduction to plugin development . If you have time to spare and want to know more about Dokka's internals, its architecture and capabilities, follow Architecture overview and subsequent sections inside Internals . Having read through all the developer guides, you'll have a pretty good unrestanding of Dokka and how to develop for it. If you have any questions, feel free to get in touch with maintainers via Slack or GitHub .","title":"Developer guides"},{"location":"developer_guide/workflow/","text":"Workflow \u00b6 Whether you're contributing a feature/fix to Dokka itself or developing a separate plugin, there's 3 things you'll be doing: Building Dokka / Plugins Using/Testing locally built Dokka in a (debug) project Debugging Dokka / Plugin code We'll go over each step individually in this section. Examples below will be specific to Gradle and Gradle\u2019s Kotlin DSL , but you can apply the same principles and run/test/debug with CLI/Maven runners and build configurations if you wish. Building Dokka \u00b6 Building Dokka is pretty straightforward, with one small caveat: when you run ./gradlew build , it will run integration tests as well, which might take some time and will consume a lot of RAM, so you would usually want to exclude integration tests when building locally. ./gradlew build -x integrationTest Unit tests which are run as part of build should not take much time, but you can also skip it with -x test . Troubleshooting build \u00b6 API check failed for project .. \u00b6 If you see messages like API check failed for project .. during build phase, it indicates that binary compatibility check has failed, meaning you've changed/added/removed some public API. If the change was intentional, run ./gradlew apiDump - it will re-generate .api files with signatures, and you should be able to build Dokka with no errors. These updated files need to be committed as well. Maintainers will review API changes thoroughly, so please make sure it's intentional and rational. Using/testing locally built Dokka \u00b6 Having built Dokka locally, you can publish it to mavenLocal() . This will allow you to test your changes in another project as well as debug code remotely. Change dokka_version in gradle.properties to something that you will use later on as the dependency version. For instance, you can set it to something like 1.8.20-my-fix-SNAPSHOT . This version will be propagated to plugins that reside inside Dokka's project (such as mathjax , kotlin-as-java , etc). Publish it to maven local ( ./gradlew publishToMavenLocal ). Corresponding artifacts should appear in ~/.m2 In the project you want to generate documentation for or debug on, add maven local as a plugin/dependency repository: repositories { mavenLocal () } Update your dokka dependency to the version you've just published: plugins { id ( \"org.jetbrains.dokka\" ) version \"1.8.20-my-fix-SNAPSHOT\" } After completing these steps, you should be able to build documentation using your own version of Dokka. Debugging Dokka \u00b6 Dokka is essentially a gradle plugin, so you can debug it the same way you would any other gradle plugin. Below you'll find instructions on how to debug Dokka's internal logic, but you can apply the same principles if you wish to debug a plugin which resides in a separate project. Choose a project to debug on, it needs to have some code for which documentation will be generated. Prefer using smaller projects that reproduce the exact problem or behaviour you want since the less code you have, the easier it will be to understand what's going on. You can use example projects found in dokka/examples/gradle , there's both simple single-module and more complex multimodule/multiplatform examples. For the debug project, set org.gradle.debug to true in one of the following ways: In your gradle.properties add org.gradle.debug=true When running Dokka tasks: ./gradlew dokkaHtml -Dorg.gradle.debug=true --no-daemon Run desired Dokka task with --no-daemon . Gradle should wait until you attach with debugger before proceeding with the task, so no need to hurry here. Example: ./gradlew dokkaHtml -Dorg.gradle.debug=true --no-daemon . Open Dokka in IntelliJ IDEA, set a breakpoint and, using remote debug in IntelliJ IDEA, Attach to process running on the default port 5005. You can do that either by creating a Remote JVM Debug Run/Debug configuration or by attaching to the process via Run -> Attach to process Note The reason for --no-daemon is that Gradle daemons continue to exist even after the task has completed execution, so you might hang in debug or experience issues with port was already in use if you try to run it again. If you previously ran Dokka with daemons and you are already encountering problems with it, try killing gradle daemons. For instance, via pkill -f gradle.*daemon In case you need to debug some other part of the build - consult the official Gradle tutorials on Troubleshooting Builds .","title":"Workflow"},{"location":"developer_guide/workflow/#workflow","text":"Whether you're contributing a feature/fix to Dokka itself or developing a separate plugin, there's 3 things you'll be doing: Building Dokka / Plugins Using/Testing locally built Dokka in a (debug) project Debugging Dokka / Plugin code We'll go over each step individually in this section. Examples below will be specific to Gradle and Gradle\u2019s Kotlin DSL , but you can apply the same principles and run/test/debug with CLI/Maven runners and build configurations if you wish.","title":"Workflow"},{"location":"developer_guide/workflow/#building-dokka","text":"Building Dokka is pretty straightforward, with one small caveat: when you run ./gradlew build , it will run integration tests as well, which might take some time and will consume a lot of RAM, so you would usually want to exclude integration tests when building locally. ./gradlew build -x integrationTest Unit tests which are run as part of build should not take much time, but you can also skip it with -x test .","title":"Building Dokka"},{"location":"developer_guide/workflow/#troubleshooting-build","text":"","title":"Troubleshooting build"},{"location":"developer_guide/workflow/#api-check-failed-for-project","text":"If you see messages like API check failed for project .. during build phase, it indicates that binary compatibility check has failed, meaning you've changed/added/removed some public API. If the change was intentional, run ./gradlew apiDump - it will re-generate .api files with signatures, and you should be able to build Dokka with no errors. These updated files need to be committed as well. Maintainers will review API changes thoroughly, so please make sure it's intentional and rational.","title":"API check failed for project .."},{"location":"developer_guide/workflow/#usingtesting-locally-built-dokka","text":"Having built Dokka locally, you can publish it to mavenLocal() . This will allow you to test your changes in another project as well as debug code remotely. Change dokka_version in gradle.properties to something that you will use later on as the dependency version. For instance, you can set it to something like 1.8.20-my-fix-SNAPSHOT . This version will be propagated to plugins that reside inside Dokka's project (such as mathjax , kotlin-as-java , etc). Publish it to maven local ( ./gradlew publishToMavenLocal ). Corresponding artifacts should appear in ~/.m2 In the project you want to generate documentation for or debug on, add maven local as a plugin/dependency repository: repositories { mavenLocal () } Update your dokka dependency to the version you've just published: plugins { id ( \"org.jetbrains.dokka\" ) version \"1.8.20-my-fix-SNAPSHOT\" } After completing these steps, you should be able to build documentation using your own version of Dokka.","title":"Using/testing locally built Dokka"},{"location":"developer_guide/workflow/#debugging-dokka","text":"Dokka is essentially a gradle plugin, so you can debug it the same way you would any other gradle plugin. Below you'll find instructions on how to debug Dokka's internal logic, but you can apply the same principles if you wish to debug a plugin which resides in a separate project. Choose a project to debug on, it needs to have some code for which documentation will be generated. Prefer using smaller projects that reproduce the exact problem or behaviour you want since the less code you have, the easier it will be to understand what's going on. You can use example projects found in dokka/examples/gradle , there's both simple single-module and more complex multimodule/multiplatform examples. For the debug project, set org.gradle.debug to true in one of the following ways: In your gradle.properties add org.gradle.debug=true When running Dokka tasks: ./gradlew dokkaHtml -Dorg.gradle.debug=true --no-daemon Run desired Dokka task with --no-daemon . Gradle should wait until you attach with debugger before proceeding with the task, so no need to hurry here. Example: ./gradlew dokkaHtml -Dorg.gradle.debug=true --no-daemon . Open Dokka in IntelliJ IDEA, set a breakpoint and, using remote debug in IntelliJ IDEA, Attach to process running on the default port 5005. You can do that either by creating a Remote JVM Debug Run/Debug configuration or by attaching to the process via Run -> Attach to process Note The reason for --no-daemon is that Gradle daemons continue to exist even after the task has completed execution, so you might hang in debug or experience issues with port was already in use if you try to run it again. If you previously ran Dokka with daemons and you are already encountering problems with it, try killing gradle daemons. For instance, via pkill -f gradle.*daemon In case you need to debug some other part of the build - consult the official Gradle tutorials on Troubleshooting Builds .","title":"Debugging Dokka"},{"location":"developer_guide/architecture/architecture_overview/","text":"Architecture overview \u00b6 Normally, you would think that a tool like Dokka simply parses some programming language sources and generates HTML pages for whatever it sees along the way, with little to no abstractions. That would be the simplest and shortest way to implement an API documentation engine. However, it was clear that Dokka may need to generate documentation from various sources (not only Kotlin ), that users might request additional output formats (like Markdown ), that users might need additional features like supporting custom KDoc tags or rendering mermaid.js diagrams - all these things would require changing a lot of code inside Dokka itself if all solutions were hardcoded. For this reason, Dokka was built from the ground up to be easily extensible and customizable by adding several layers of abstractions to the data model, and by providing pluggable extension points, giving you the ability to introduce selective changes on a single level. Overview of data model \u00b6 Generating API documentation begins with Input source files ( .kts , .java , etc) and ends with some Output files ( .html / .md pages, etc). However, to allow for extensibility and customization, several input and output independent abstractions have been added to the data model. Below you can find the general pipeline of processing data gathered from sources and the explanation for each stage. flowchart TD Input --> Documentables --> Pages --> Output Input - generalization of sources, by default Kotlin / Java sources, but could be virtually anything Documentables - unified data model that represents any parsed sources as a tree, independent of the source language. Examples of a Documentable : class, function, package, property, etc Pages - universal model that represents output pages (e.g a function/property page) and the content it's composed of (lists, text, code blocks) that the users needs to see. Not to be confused with .html pages. Goes hand in hand with so-called Content model. Output - specific output format like HTML / Markdown / Javadoc /etc. This is a mapping of pages/content model to some human-readable and visual representation. For instance: PageNode is mapped as .html file for HTML format .md file for Markdown format ContentList is mapped as <li> / <ul> for HTML format 1. / * for Markdown format ContentCodeBlock is mapped as <code> or <pre> with some CSS styles in HTML format Text wrapped in triple backticks for Markdown format You, as a Dokka developer or a plugin writer, can use extension points to introduce selective changes to the model on one particular level without touching everything else. For instance, if you wanted to make some annotation/function/class invisible in the final documentation, you would only need to modify the Documentables model by filtering undesirable members out. If you wanted to display all overloaded methods on the same page instead of on separate ones, you would only need to modify the Page model by merging multiple pages into one, and so on. For a deeper dive into Dokka's model with more examples and details, see sections about Documentables and Page/Content For an overview of existing extension points that let you transform Dokka's models, see Core extension points and Base extensions . Overview of extension points \u00b6 An extension point usually represents some pluggable interface that performs an action during one of the stages of generating documentation. An extension is therefore an implementation of that interface which is extending the extension point. You can create extension points, provide your own implementations (extensions) and configure them. All of this is possible with Dokka's plugin/extension point API. Here's a sneak peek of the DSL: class MyPlugin : DokkaPlugin () { // create an extension point for other developers val signatureProvider by extensionPoint < SignatureProvider > () // provide a default implementation val defaultSignatureProvider by extending { signatureProvider with KotlinSignatureProvider () } // register our own extension in base plugin and override its default val dokkaBasePlugin by lazy { plugin < DokkaBase > () } val multimoduleLocationProvider by extending { ( dokkaBasePlugin . locationProviderFactory providing MultimoduleLocationProvider :: Factory override dokkaBasePlugin . locationProvider ) } } // use a registered extention, pretty much dependency injection class MyExtension ( val context : DokkaContext ) { val signatureProvider : SignatureProvider = context . plugin < MyPlugin > (). querySingle { signatureProvider } fun doSomething () { signatureProvider . signature (..) } } interface SignatureProvider { fun signature ( documentable : Documentable ): List < ContentNode > } class KotlinSignatureProvider : SignatureProvider { override fun signature ( documentable : Documentable ): List < ContentNode > = listOf () } For a deeper dive into extensions and extension points with more examples and details, see Introduction to Extensions . For an overview of existing extension points, see Core extension points and Base extensions . Historical context \u00b6 This is a second iteration of Dokka that was built from scratch. If you want to learn more about why Dokka has been designed this way, watch this great talk by Pawe\u0142 Marks: New Dokka - Designed for Fearless Creativity . The general principles and general architecture are the same, although it may be outdated in some areas, so please double-check.","title":"Architecture"},{"location":"developer_guide/architecture/architecture_overview/#architecture-overview","text":"Normally, you would think that a tool like Dokka simply parses some programming language sources and generates HTML pages for whatever it sees along the way, with little to no abstractions. That would be the simplest and shortest way to implement an API documentation engine. However, it was clear that Dokka may need to generate documentation from various sources (not only Kotlin ), that users might request additional output formats (like Markdown ), that users might need additional features like supporting custom KDoc tags or rendering mermaid.js diagrams - all these things would require changing a lot of code inside Dokka itself if all solutions were hardcoded. For this reason, Dokka was built from the ground up to be easily extensible and customizable by adding several layers of abstractions to the data model, and by providing pluggable extension points, giving you the ability to introduce selective changes on a single level.","title":"Architecture overview"},{"location":"developer_guide/architecture/architecture_overview/#overview-of-data-model","text":"Generating API documentation begins with Input source files ( .kts , .java , etc) and ends with some Output files ( .html / .md pages, etc). However, to allow for extensibility and customization, several input and output independent abstractions have been added to the data model. Below you can find the general pipeline of processing data gathered from sources and the explanation for each stage. flowchart TD Input --> Documentables --> Pages --> Output Input - generalization of sources, by default Kotlin / Java sources, but could be virtually anything Documentables - unified data model that represents any parsed sources as a tree, independent of the source language. Examples of a Documentable : class, function, package, property, etc Pages - universal model that represents output pages (e.g a function/property page) and the content it's composed of (lists, text, code blocks) that the users needs to see. Not to be confused with .html pages. Goes hand in hand with so-called Content model. Output - specific output format like HTML / Markdown / Javadoc /etc. This is a mapping of pages/content model to some human-readable and visual representation. For instance: PageNode is mapped as .html file for HTML format .md file for Markdown format ContentList is mapped as <li> / <ul> for HTML format 1. / * for Markdown format ContentCodeBlock is mapped as <code> or <pre> with some CSS styles in HTML format Text wrapped in triple backticks for Markdown format You, as a Dokka developer or a plugin writer, can use extension points to introduce selective changes to the model on one particular level without touching everything else. For instance, if you wanted to make some annotation/function/class invisible in the final documentation, you would only need to modify the Documentables model by filtering undesirable members out. If you wanted to display all overloaded methods on the same page instead of on separate ones, you would only need to modify the Page model by merging multiple pages into one, and so on. For a deeper dive into Dokka's model with more examples and details, see sections about Documentables and Page/Content For an overview of existing extension points that let you transform Dokka's models, see Core extension points and Base extensions .","title":"Overview of data model"},{"location":"developer_guide/architecture/architecture_overview/#overview-of-extension-points","text":"An extension point usually represents some pluggable interface that performs an action during one of the stages of generating documentation. An extension is therefore an implementation of that interface which is extending the extension point. You can create extension points, provide your own implementations (extensions) and configure them. All of this is possible with Dokka's plugin/extension point API. Here's a sneak peek of the DSL: class MyPlugin : DokkaPlugin () { // create an extension point for other developers val signatureProvider by extensionPoint < SignatureProvider > () // provide a default implementation val defaultSignatureProvider by extending { signatureProvider with KotlinSignatureProvider () } // register our own extension in base plugin and override its default val dokkaBasePlugin by lazy { plugin < DokkaBase > () } val multimoduleLocationProvider by extending { ( dokkaBasePlugin . locationProviderFactory providing MultimoduleLocationProvider :: Factory override dokkaBasePlugin . locationProvider ) } } // use a registered extention, pretty much dependency injection class MyExtension ( val context : DokkaContext ) { val signatureProvider : SignatureProvider = context . plugin < MyPlugin > (). querySingle { signatureProvider } fun doSomething () { signatureProvider . signature (..) } } interface SignatureProvider { fun signature ( documentable : Documentable ): List < ContentNode > } class KotlinSignatureProvider : SignatureProvider { override fun signature ( documentable : Documentable ): List < ContentNode > = listOf () } For a deeper dive into extensions and extension points with more examples and details, see Introduction to Extensions . For an overview of existing extension points, see Core extension points and Base extensions .","title":"Overview of extension points"},{"location":"developer_guide/architecture/architecture_overview/#historical-context","text":"This is a second iteration of Dokka that was built from scratch. If you want to learn more about why Dokka has been designed this way, watch this great talk by Pawe\u0142 Marks: New Dokka - Designed for Fearless Creativity . The general principles and general architecture are the same, although it may be outdated in some areas, so please double-check.","title":"Historical context"},{"location":"developer_guide/architecture/data_model/documentables/","text":"Documentables Model \u00b6 Documentables represent data that is parsed from sources. Think of this data model as of something that could be seen or produced by a compiler frontend, it's not far off from the truth. By default, documentables are parsed from Descriptor (for Kotlin ) and Psi (for Java ) models. Code-wise, you can have a look at following classes: DefaultDescriptorToDocumentableTranslator - responsible for Kotlin -> Documentable mapping DefaultPsiToDocumentableTranslator - responsible for Java -> Documentable mapping Upon creation, it's a collection of trees, each with DModule as root. Take some arbitrary Kotlin source code that is located within the same module: // Package 1 class Clazz ( val property : String ) { fun function ( parameter : String ) {} } fun topLevelFunction () {} // Package 2 enum class Enum { } val topLevelProperty : String This would be represented roughly as the following Documentable tree: flowchart TD DModule --> firstPackage[DPackage] firstPackage --> DClass firstPackage --> toplevelfunction[DFunction] DClass --> DProperty DClass --> DFunction DFunction --> DParameter DModule --> secondPackage[DPackage] secondPackage --> DEnum secondPackage --> secondPackageProperty[DProperty] At later stages of transformation, all trees are folded into one (by DocumentableMerger ). Documentable \u00b6 The main building block of documentables model is Documentable class. It's the base class for all more specific types that represent elements of parsed sources with mostly self-explanatory names ( DFunction , DPackage , DProperty , etc) . DClasslike is the base class for class-like documentables such as DClass , DEnum , DAnnotation , etc. The contents of each documentable normally represent what you would see in source code. For instance, if you open DClass , you should find that it contains references to functions, properties, companion object, constructors and so on. DEnum should have references to enum entries, and DPackage can have references to both classlikes and top-level functions and properties ( Kotlin -specific). Here's an example of a documentable: data class DClass ( val dri : DRI , val name : String , val constructors : List < DFunction > , val functions : List < DFunction > , val properties : List < DProperty > , val classlikes : List < DClasslike > , val sources : SourceSetDependent < DocumentableSource > , val visibility : SourceSetDependent < Visibility > , val companion : DObject?, val generics : List < DTypeParameter > , val supertypes : SourceSetDependent < List < TypeConstructorWithKind >> , val documentation : SourceSetDependent < DocumentationNode > , val expectPresentInSet : DokkaSourceSet?, val modifier : SourceSetDependent < Modifier > , val sourceSets : Set < DokkaSourceSet > , val isExpectActual : Boolean , val extra : PropertyContainer < DClass > = PropertyContainer . empty () ) : DClasslike (), WithAbstraction , WithCompanion , WithConstructors , WithGenerics , WithSupertypes , WithExtraProperties < DClass > There are three non-documentable classes that important for this model: DRI SourceSetDependent ExtraProperty . DRI \u00b6 DRI stans for Dokka Resource Identifier - a unique value that identifies a specific Documentable . All references and relations between documentables (other than direct ownership) are described using DRI . For example, DFunction with a parameter of type Foo has only Foo 's DRI , not the actual reference to Foo 's Documentable object. Example \u00b6 For an example of how a DRI can look like, let's take the limitedParallelism function from kotlinx.coroutines : package kotlinx.coroutines import ... public abstract class MainCoroutineDispatcher : CoroutineDispatcher () { override fun limitedParallelism ( parallelism : Int ): CoroutineDispatcher { ... } } If we were to re-create the DRI of this function in code, it would look something like this: DRI ( packageName = \"kotlinx.coroutines\" , classNames = \"MainCoroutineDispatcher\" , callable = Callable ( name = \"limitedParallelism\" , receiver = null , params = listOf ( TypeConstructor ( fullyQualifiedName = \"kotlin.Int\" , params = emptyList () ) ) ), target = PointingToDeclaration , extra = null ) If you format it as String , it would look like this: kotlinx.coroutines/MainCoroutineDispatcher/limitedParallelism/#kotlin.Int/PointingToDeclaration/ SourceSetDependent \u00b6 SourceSetDependent helps handling multiplatform data by associating platform-specific data (declared with either expect or actual modifier) with particular source sets . This comes in handy if expect / actual declarations differ. For instance, the default value for actual might differ from that declared in expect , or code comments written for expect might be different from what's written for actual . Under the hood, it's a typealias to a Map : typealias SourceSetDependent < T > = Map < DokkaSourceSet , T > ExtraProperty \u00b6 ExtraProperty is used to store any additional information that falls outside of the regular model. It is highly recommended to use extras to provide any additional information when creating custom Dokka plugins. This element is a bit more complex, so you can read more about how to use it in a separate section . Documentation model \u00b6 Documentation model is used alongside Documentables to store data obtained by parsing code comments (such as KDoc / Javadoc ). DocTag \u00b6 DocTag describes a specific documentation syntax element. It's universal across source languages. For instance, DocTag B is the same for **bold** in Kotlin and <b>bold</b> in Java . However, some DocTag elements are specific to a certain language, there are many such examples for Java because it allows HTML tags inside Javadoc comments, some of which are simply not possible to reproduce with Markdown . DocTag elements can be deeply nested with other DocTag children elements. Examples: data class H1 ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class H2 ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class Strikethrough ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class Strong ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class CodeBlock ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : Code () TagWrapper \u00b6 TagWrapper describes the whole comment description or a specific comment tag. For example: @see / @author / @return . Since each such section may contain formatted text inside of it, each TagWrapper has DocTag children. /** * @author **Ben Affleck* * @return nothing, except _sometimes_ it may throw an [Error] */ fun foo () {} DocumentationNode \u00b6 DocumentationNode acts as a container for multiple TagWrapper elements for a specific Documentable , usually used like this: data class DFunction ( ... val documentation : SourceSetDependent < DocumentationNode > , ... )","title":"Documentables"},{"location":"developer_guide/architecture/data_model/documentables/#documentables-model","text":"Documentables represent data that is parsed from sources. Think of this data model as of something that could be seen or produced by a compiler frontend, it's not far off from the truth. By default, documentables are parsed from Descriptor (for Kotlin ) and Psi (for Java ) models. Code-wise, you can have a look at following classes: DefaultDescriptorToDocumentableTranslator - responsible for Kotlin -> Documentable mapping DefaultPsiToDocumentableTranslator - responsible for Java -> Documentable mapping Upon creation, it's a collection of trees, each with DModule as root. Take some arbitrary Kotlin source code that is located within the same module: // Package 1 class Clazz ( val property : String ) { fun function ( parameter : String ) {} } fun topLevelFunction () {} // Package 2 enum class Enum { } val topLevelProperty : String This would be represented roughly as the following Documentable tree: flowchart TD DModule --> firstPackage[DPackage] firstPackage --> DClass firstPackage --> toplevelfunction[DFunction] DClass --> DProperty DClass --> DFunction DFunction --> DParameter DModule --> secondPackage[DPackage] secondPackage --> DEnum secondPackage --> secondPackageProperty[DProperty] At later stages of transformation, all trees are folded into one (by DocumentableMerger ).","title":"Documentables Model"},{"location":"developer_guide/architecture/data_model/documentables/#documentable","text":"The main building block of documentables model is Documentable class. It's the base class for all more specific types that represent elements of parsed sources with mostly self-explanatory names ( DFunction , DPackage , DProperty , etc) . DClasslike is the base class for class-like documentables such as DClass , DEnum , DAnnotation , etc. The contents of each documentable normally represent what you would see in source code. For instance, if you open DClass , you should find that it contains references to functions, properties, companion object, constructors and so on. DEnum should have references to enum entries, and DPackage can have references to both classlikes and top-level functions and properties ( Kotlin -specific). Here's an example of a documentable: data class DClass ( val dri : DRI , val name : String , val constructors : List < DFunction > , val functions : List < DFunction > , val properties : List < DProperty > , val classlikes : List < DClasslike > , val sources : SourceSetDependent < DocumentableSource > , val visibility : SourceSetDependent < Visibility > , val companion : DObject?, val generics : List < DTypeParameter > , val supertypes : SourceSetDependent < List < TypeConstructorWithKind >> , val documentation : SourceSetDependent < DocumentationNode > , val expectPresentInSet : DokkaSourceSet?, val modifier : SourceSetDependent < Modifier > , val sourceSets : Set < DokkaSourceSet > , val isExpectActual : Boolean , val extra : PropertyContainer < DClass > = PropertyContainer . empty () ) : DClasslike (), WithAbstraction , WithCompanion , WithConstructors , WithGenerics , WithSupertypes , WithExtraProperties < DClass > There are three non-documentable classes that important for this model: DRI SourceSetDependent ExtraProperty .","title":"Documentable"},{"location":"developer_guide/architecture/data_model/documentables/#dri","text":"DRI stans for Dokka Resource Identifier - a unique value that identifies a specific Documentable . All references and relations between documentables (other than direct ownership) are described using DRI . For example, DFunction with a parameter of type Foo has only Foo 's DRI , not the actual reference to Foo 's Documentable object.","title":"DRI"},{"location":"developer_guide/architecture/data_model/documentables/#example","text":"For an example of how a DRI can look like, let's take the limitedParallelism function from kotlinx.coroutines : package kotlinx.coroutines import ... public abstract class MainCoroutineDispatcher : CoroutineDispatcher () { override fun limitedParallelism ( parallelism : Int ): CoroutineDispatcher { ... } } If we were to re-create the DRI of this function in code, it would look something like this: DRI ( packageName = \"kotlinx.coroutines\" , classNames = \"MainCoroutineDispatcher\" , callable = Callable ( name = \"limitedParallelism\" , receiver = null , params = listOf ( TypeConstructor ( fullyQualifiedName = \"kotlin.Int\" , params = emptyList () ) ) ), target = PointingToDeclaration , extra = null ) If you format it as String , it would look like this: kotlinx.coroutines/MainCoroutineDispatcher/limitedParallelism/#kotlin.Int/PointingToDeclaration/","title":"Example"},{"location":"developer_guide/architecture/data_model/documentables/#sourcesetdependent","text":"SourceSetDependent helps handling multiplatform data by associating platform-specific data (declared with either expect or actual modifier) with particular source sets . This comes in handy if expect / actual declarations differ. For instance, the default value for actual might differ from that declared in expect , or code comments written for expect might be different from what's written for actual . Under the hood, it's a typealias to a Map : typealias SourceSetDependent < T > = Map < DokkaSourceSet , T >","title":"SourceSetDependent"},{"location":"developer_guide/architecture/data_model/documentables/#extraproperty","text":"ExtraProperty is used to store any additional information that falls outside of the regular model. It is highly recommended to use extras to provide any additional information when creating custom Dokka plugins. This element is a bit more complex, so you can read more about how to use it in a separate section .","title":"ExtraProperty"},{"location":"developer_guide/architecture/data_model/documentables/#documentation-model","text":"Documentation model is used alongside Documentables to store data obtained by parsing code comments (such as KDoc / Javadoc ).","title":"Documentation model"},{"location":"developer_guide/architecture/data_model/documentables/#doctag","text":"DocTag describes a specific documentation syntax element. It's universal across source languages. For instance, DocTag B is the same for **bold** in Kotlin and <b>bold</b> in Java . However, some DocTag elements are specific to a certain language, there are many such examples for Java because it allows HTML tags inside Javadoc comments, some of which are simply not possible to reproduce with Markdown . DocTag elements can be deeply nested with other DocTag children elements. Examples: data class H1 ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class H2 ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class Strikethrough ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class Strong ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : DocTag () data class CodeBlock ( override val children : List < DocTag > = emptyList (), override val params : Map < String , String > = emptyMap () ) : Code ()","title":"DocTag"},{"location":"developer_guide/architecture/data_model/documentables/#tagwrapper","text":"TagWrapper describes the whole comment description or a specific comment tag. For example: @see / @author / @return . Since each such section may contain formatted text inside of it, each TagWrapper has DocTag children. /** * @author **Ben Affleck* * @return nothing, except _sometimes_ it may throw an [Error] */ fun foo () {}","title":"TagWrapper"},{"location":"developer_guide/architecture/data_model/documentables/#documentationnode","text":"DocumentationNode acts as a container for multiple TagWrapper elements for a specific Documentable , usually used like this: data class DFunction ( ... val documentation : SourceSetDependent < DocumentationNode > , ... )","title":"DocumentationNode"},{"location":"developer_guide/architecture/data_model/extra/","text":"Extra \u00b6 Introduction \u00b6 ExtraProperty classes are used both by Documentable and Content models. Source code for ExtraProperty : interface ExtraProperty < in C : Any > { interface Key < in C : Any , T : Any > { fun mergeStrategyFor ( left : T , right : T ): MergeStrategy < C > = MergeStrategy . Fail { throw NotImplementedError ( \"Property merging for $ this is not implemented\" ) } } val key : Key < C , *> } To declare a new extra, you need to implement ExtraProperty interface. It is advised to use following pattern when declaring new extras: data class CustomExtra ( [ any data relevant to your extra ] , [ any data relevant to your extra ] ): ExtraProperty < Documentable > { override val key : CustomExtra . Key < Documentable , *> = CustomExtra companion object : CustomExtra . Key < Documentable , CustomExtra > } Merge strategy ( mergeStrategyFor method) for extras is invoked during merging if documentables from different source sets each have their own Extra of the same type. PropertyContainer \u00b6 All extras for ContentNode and Documentable classes are stored in PropertyContainer<C : Any> class instances. data class DFunction ( ... override val extra : PropertyContainer < DFunction > = PropertyContainer . empty () ... ) : WithExtraProperties < DFunction > PropertyContainer has a number of convenient functions for handling extras in a collection-like manner. The C generic class parameter limits the type of properties that can be stored in the container - it must match generic C class parameter from ExtraProperty interface. This allows creating extra properties which can only be stored in a specific Documentable . Usage example \u00b6 In following example we will create a DFunction -only property, store it and then retrieve its value: data class CustomExtra ( val customExtraValue : String ) : ExtraProperty < DFunction > { override val key : ExtraProperty . Key < Documentable , *> = CustomExtra companion object : ExtraProperty . Key < Documentable , CustomExtra > } fun DFunction . withCustomExtraProperty ( data : String ): DFunction { return this . copy ( extra = extra + CustomExtra ( data ) ) } fun DFunction . getCustomExtraPropertyValue (): String? { return this . extra [ CustomExtra ]?. customExtraValue } You can also use extras as markers, without storing any data in them: object MarkerExtra : ExtraProperty < Any > , ExtraProperty . Key < Any , MarkerExtra > { override val key : ExtraProperty . Key < Any , *> = this } fun Documentable . markIfFunction (): Documentable { return when ( this ) { is DFunction -> this . copy ( extra = extra + MarkerExtra ) else -> this } } fun WithExtraProperties < Documentable > . isMarked (): Boolean { return this . extra [ MarkerExtra ] != null }","title":"Extra properties"},{"location":"developer_guide/architecture/data_model/extra/#extra","text":"","title":"Extra"},{"location":"developer_guide/architecture/data_model/extra/#introduction","text":"ExtraProperty classes are used both by Documentable and Content models. Source code for ExtraProperty : interface ExtraProperty < in C : Any > { interface Key < in C : Any , T : Any > { fun mergeStrategyFor ( left : T , right : T ): MergeStrategy < C > = MergeStrategy . Fail { throw NotImplementedError ( \"Property merging for $ this is not implemented\" ) } } val key : Key < C , *> } To declare a new extra, you need to implement ExtraProperty interface. It is advised to use following pattern when declaring new extras: data class CustomExtra ( [ any data relevant to your extra ] , [ any data relevant to your extra ] ): ExtraProperty < Documentable > { override val key : CustomExtra . Key < Documentable , *> = CustomExtra companion object : CustomExtra . Key < Documentable , CustomExtra > } Merge strategy ( mergeStrategyFor method) for extras is invoked during merging if documentables from different source sets each have their own Extra of the same type.","title":"Introduction"},{"location":"developer_guide/architecture/data_model/extra/#propertycontainer","text":"All extras for ContentNode and Documentable classes are stored in PropertyContainer<C : Any> class instances. data class DFunction ( ... override val extra : PropertyContainer < DFunction > = PropertyContainer . empty () ... ) : WithExtraProperties < DFunction > PropertyContainer has a number of convenient functions for handling extras in a collection-like manner. The C generic class parameter limits the type of properties that can be stored in the container - it must match generic C class parameter from ExtraProperty interface. This allows creating extra properties which can only be stored in a specific Documentable .","title":"PropertyContainer"},{"location":"developer_guide/architecture/data_model/extra/#usage-example","text":"In following example we will create a DFunction -only property, store it and then retrieve its value: data class CustomExtra ( val customExtraValue : String ) : ExtraProperty < DFunction > { override val key : ExtraProperty . Key < Documentable , *> = CustomExtra companion object : ExtraProperty . Key < Documentable , CustomExtra > } fun DFunction . withCustomExtraProperty ( data : String ): DFunction { return this . copy ( extra = extra + CustomExtra ( data ) ) } fun DFunction . getCustomExtraPropertyValue (): String? { return this . extra [ CustomExtra ]?. customExtraValue } You can also use extras as markers, without storing any data in them: object MarkerExtra : ExtraProperty < Any > , ExtraProperty . Key < Any , MarkerExtra > { override val key : ExtraProperty . Key < Any , *> = this } fun Documentable . markIfFunction (): Documentable { return when ( this ) { is DFunction -> this . copy ( extra = extra + MarkerExtra ) else -> this } } fun WithExtraProperties < Documentable > . isMarked (): Boolean { return this . extra [ MarkerExtra ] != null }","title":"Usage example"},{"location":"developer_guide/architecture/data_model/page_content/","text":"Page / Content Model \u00b6 Even though Page and Content models reside on the same level (under Page ), it's easier to view it as two different models altogether, even though Content is only used in conjunction with and inside Page model. Page \u00b6 Page model represents the structure of documentation pages to be generated. During rendering, each page is processed separately, so one page corresponds to exactly one output file. Page model is independent of the final output format, in other words it's universal. Which extension the pages should be created as ( .html , .md , etc) and how is up to the Renderer . Subclasses of PageNode represent different kinds of rendered pages, such as ModulePage , PackagePage , ClasslikePage , MemberPage (properties, functions), etc. The Page Model is a tree structure, with RootPageNode at the root. Here's an example of how an arbitrary Page tree might look like for a module with 3 packages, one of which contains a top level function, top level property and a class, inside which there's a function and a property: flowchart TD RootPageNode --> firstPackage[PackagePageNode] RootPageNode --> secondPackage[PackagePageNode] RootPageNode --> thirdPackage[PackagePageNode] firstPackage --> firstPackageFirstMember[MemberPageNode - Function] firstPackage --> firstPackageSecondMember[MemberPageNode - Property] firstPackage ---> firstPackageClasslike[ClasslikePageNode - Class] firstPackageClasslike --> firstPackageClasslikeFirstMember[MemberPageNode - Function] firstPackageClasslike --> firstPackageClasslikeSecondMember[MemberPageNode - Property] secondPackage --> etcOne[...] thirdPackage --> etcTwo[...] Almost all pages are derivatives of ContentPage - it's the type of Page that has Content on it. Content Model \u00b6 Content model describes how the actual Page content is presented. The important thing to understand is that it's also output-format independent and is universal. Content model is essentially a set of building blocks that you can put together to represent some content. Have a look at subclasses of ContentNode : ContentText , ContentList , ContentTable , ContentCodeBlock , ContentHeader and so on. You can group content together with ContentGroup - for instance, to wrap all children with some style. // real example of composing content using `DocumentableContentBuilder` DSL orderedList { item { text ( \"This list contains a nested table:\" ) table { header { text ( \"Col1\" ) text ( \"Col2\" ) } row { text ( \"Text1\" ) text ( \"Text2\" ) } } } item { group ( styles = setOf ( TextStyle . Bold )) { text ( \"This is bald\" ) text ( \"This is also bald\" ) } } } It is then responsibility of Renderer (i.e specific output format) to render it the way it wants. For instance, HtmlRenderer might render ContentCodeBlock as <code>text</code> , but CommonmarkRenderer might render it using backticks. DCI \u00b6 Each node is identified by unique DCI , which stands for Dokka Content Identifier . DCI aggregates DRI s of all Documentables that make up a specific ContentNode . data class DCI ( val dri : Set < DRI > , val kind : Kind ) All references to other nodes (other than direct ownership) are described using DCI . ContentKind \u00b6 ContentKind represents a grouping of content of one kind that can can be rendered as part of a composite page (one tab/block within a class's page, for instance). For instance, on the same page that describes a class you can have multiple sections (== ContentKind ). One to describe functions, one to describe properties, another one to describe constructors and so on. Styles \u00b6 Each ContentNode has styles property in case you want to incidate to Renderer that this content needs to be displayed in a certain way. group ( styles = setOf ( TextStyle . Paragraph )) { text ( \"Text1\" , styles = setOf ( TextStyle . Bold )) text ( \"Text2\" , styles = setOf ( TextStyle . Italic )) } It is then responsibility of Renderer (i.e specific output format) to render it the way it wants. For instance, HtmlRenderer might render TextStyle.Bold as <b>text</b> , but CommonmarkRenderer might render it as **text** . There's a number of existing styles that you can use, most of them are supported by HtmlRenderer out of the box: // for code highlighting enum class TokenStyle : Style { Keyword , Punctuation , Function , Operator , Annotation , Number , String , Boolean , Constant , Builtin , ... } enum class TextStyle : Style { Bold , Italic , Strong , Strikethrough , Paragraph , ... } enum class ContentStyle : Style { TabbedContent , RunnableSample , Wrapped , Indented , ... } Extra \u00b6 ExtraProperty is used to store any additional information that falls outside of the regular model. It is highly recommended to use extras to provide any additional information when creating custom Dokka plugins. All ExtraProperty elements from Documentable model are propagated into Content model and are available for Renderer . This element is a bit complex, so you can read more about how to use it in a separate section .","title":"Page & Content"},{"location":"developer_guide/architecture/data_model/page_content/#page-content-model","text":"Even though Page and Content models reside on the same level (under Page ), it's easier to view it as two different models altogether, even though Content is only used in conjunction with and inside Page model.","title":"Page / Content Model"},{"location":"developer_guide/architecture/data_model/page_content/#page","text":"Page model represents the structure of documentation pages to be generated. During rendering, each page is processed separately, so one page corresponds to exactly one output file. Page model is independent of the final output format, in other words it's universal. Which extension the pages should be created as ( .html , .md , etc) and how is up to the Renderer . Subclasses of PageNode represent different kinds of rendered pages, such as ModulePage , PackagePage , ClasslikePage , MemberPage (properties, functions), etc. The Page Model is a tree structure, with RootPageNode at the root. Here's an example of how an arbitrary Page tree might look like for a module with 3 packages, one of which contains a top level function, top level property and a class, inside which there's a function and a property: flowchart TD RootPageNode --> firstPackage[PackagePageNode] RootPageNode --> secondPackage[PackagePageNode] RootPageNode --> thirdPackage[PackagePageNode] firstPackage --> firstPackageFirstMember[MemberPageNode - Function] firstPackage --> firstPackageSecondMember[MemberPageNode - Property] firstPackage ---> firstPackageClasslike[ClasslikePageNode - Class] firstPackageClasslike --> firstPackageClasslikeFirstMember[MemberPageNode - Function] firstPackageClasslike --> firstPackageClasslikeSecondMember[MemberPageNode - Property] secondPackage --> etcOne[...] thirdPackage --> etcTwo[...] Almost all pages are derivatives of ContentPage - it's the type of Page that has Content on it.","title":"Page"},{"location":"developer_guide/architecture/data_model/page_content/#content-model","text":"Content model describes how the actual Page content is presented. The important thing to understand is that it's also output-format independent and is universal. Content model is essentially a set of building blocks that you can put together to represent some content. Have a look at subclasses of ContentNode : ContentText , ContentList , ContentTable , ContentCodeBlock , ContentHeader and so on. You can group content together with ContentGroup - for instance, to wrap all children with some style. // real example of composing content using `DocumentableContentBuilder` DSL orderedList { item { text ( \"This list contains a nested table:\" ) table { header { text ( \"Col1\" ) text ( \"Col2\" ) } row { text ( \"Text1\" ) text ( \"Text2\" ) } } } item { group ( styles = setOf ( TextStyle . Bold )) { text ( \"This is bald\" ) text ( \"This is also bald\" ) } } } It is then responsibility of Renderer (i.e specific output format) to render it the way it wants. For instance, HtmlRenderer might render ContentCodeBlock as <code>text</code> , but CommonmarkRenderer might render it using backticks.","title":"Content Model"},{"location":"developer_guide/architecture/data_model/page_content/#dci","text":"Each node is identified by unique DCI , which stands for Dokka Content Identifier . DCI aggregates DRI s of all Documentables that make up a specific ContentNode . data class DCI ( val dri : Set < DRI > , val kind : Kind ) All references to other nodes (other than direct ownership) are described using DCI .","title":"DCI"},{"location":"developer_guide/architecture/data_model/page_content/#contentkind","text":"ContentKind represents a grouping of content of one kind that can can be rendered as part of a composite page (one tab/block within a class's page, for instance). For instance, on the same page that describes a class you can have multiple sections (== ContentKind ). One to describe functions, one to describe properties, another one to describe constructors and so on.","title":"ContentKind"},{"location":"developer_guide/architecture/data_model/page_content/#styles","text":"Each ContentNode has styles property in case you want to incidate to Renderer that this content needs to be displayed in a certain way. group ( styles = setOf ( TextStyle . Paragraph )) { text ( \"Text1\" , styles = setOf ( TextStyle . Bold )) text ( \"Text2\" , styles = setOf ( TextStyle . Italic )) } It is then responsibility of Renderer (i.e specific output format) to render it the way it wants. For instance, HtmlRenderer might render TextStyle.Bold as <b>text</b> , but CommonmarkRenderer might render it as **text** . There's a number of existing styles that you can use, most of them are supported by HtmlRenderer out of the box: // for code highlighting enum class TokenStyle : Style { Keyword , Punctuation , Function , Operator , Annotation , Number , String , Boolean , Constant , Builtin , ... } enum class TextStyle : Style { Bold , Italic , Strong , Strikethrough , Paragraph , ... } enum class ContentStyle : Style { TabbedContent , RunnableSample , Wrapped , Indented , ... }","title":"Styles"},{"location":"developer_guide/architecture/data_model/page_content/#extra","text":"ExtraProperty is used to store any additional information that falls outside of the regular model. It is highly recommended to use extras to provide any additional information when creating custom Dokka plugins. All ExtraProperty elements from Documentable model are propagated into Content model and are available for Renderer . This element is a bit complex, so you can read more about how to use it in a separate section .","title":"Extra"},{"location":"developer_guide/architecture/extension_points/base_extensions/","text":"Base extensions \u00b6 DokkaBase class is a base plugin which defines a number of default implementations for CoreExtensions as well as declares its own, more high-level extension points to be used from other plugins and output formats. It's very convenient to use extension points and defaults defined in DokkaBase if you have an idea for a simple plugin that only needs to provide a few extensions or change a single extension point and have everything else be the default. DokkaBase is used extensively for Dokka's own output formats such as HTML , Markdown , Mathjax and others. You can learn how to add/use/override/configure extensions and extension points in Introduction to Extensions , all the information is applicable to DokkaBase plugin as well.","title":"Base extensions"},{"location":"developer_guide/architecture/extension_points/base_extensions/#base-extensions","text":"DokkaBase class is a base plugin which defines a number of default implementations for CoreExtensions as well as declares its own, more high-level extension points to be used from other plugins and output formats. It's very convenient to use extension points and defaults defined in DokkaBase if you have an idea for a simple plugin that only needs to provide a few extensions or change a single extension point and have everything else be the default. DokkaBase is used extensively for Dokka's own output formats such as HTML , Markdown , Mathjax and others. You can learn how to add/use/override/configure extensions and extension points in Introduction to Extensions , all the information is applicable to DokkaBase plugin as well.","title":"Base extensions"},{"location":"developer_guide/architecture/extension_points/core_extensions/","text":"Core extension points \u00b6 Core extension points represent the main stages of generating documentation. These extension points are plugin and output format independent, meaning it's the very core functionality and as low-level as can get. For higher-level extension functions that can be used in different output formats, have a look at Base extensions defined in DokkaBase . You can find all core extensions in CoreExtensions class: object CoreExtensions { val preGenerationCheck by coreExtensionPoint < PreGenerationChecker > () val generation by coreExtensionPoint < Generation > () val sourceToDocumentableTranslator by coreExtensionPoint < SourceToDocumentableTranslator > () val documentableMerger by coreExtensionPoint < DocumentableMerger > () val documentableTransformer by coreExtensionPoint < DocumentableTransformer > () val documentableToPageTranslator by coreExtensionPoint < DocumentableToPageTranslator > () val pageTransformer by coreExtensionPoint < PageTransformer > () val renderer by coreExtensionPoint < Renderer > () val postActions by coreExtensionPoint < PostAction > () } On this page we'll go over each extension point individually. PreGenerationChecker \u00b6 PreGenerationChecker can be used to run some checks and constraints. For instance, Javadoc plugin does not support generating documentation for multi-platform projects, so it uses PreGenerationChecker to check for multi-platform source sets and fails if it finds any. Generation \u00b6 Generation is responsible for generating documentation as a whole, utilizing other extension points where applicable. There are two implementations at the moment: AllModulesPageGeneration - generates multimodule documentation, for instance when dokkaHtmlMultiModule task is invoked. SingleModuleGeneration - generates documentation for a single module, for instance when dokkaHtml task is invoked AllModulesPageGeneration \u00b6 AllModulesPageGeneration utilizes output generated by SingleModuleGeneration . Under the hood it just collects all pages generated for individual modules and assembles everything together, creating navigation pages between the modules and so on. SingleModuleGeneration stages \u00b6 When developing a feature or a plugin, it's more convenient to think that you are generating documentation for single module projects, believing that Dokka will somehow take care of the rest in multimodule environment. SingleModuleGeneration is at heart of generating documentation and utilizes other core extension points, so it's worth going over its stages. Below you can see the transformations of Dokka's models and extension interfaces responsible for each one. Notice how Documentables and Pages are transformed multiple times. flowchart TD Input -- SourceToDocumentableTranslator --> doc1[Documentables] subgraph documentables [ ] doc1 -- PreMergeDocumentableTransformer --> doc2[Documentables] doc2 -- DocumentableMerger --> doc3[Documentables] doc3 -- DocumentableTransformer --> doc4[Documentables] end doc4 -- DocumentableToPageTranslator --> page1[Pages] subgraph ide2 [ ] page1 -- PageTransformer --> page2[Pages] end page2 -- Renderer --> Output SourceToDocumentableTranslator \u00b6 SourceToDocumentableTranslator translates sources into documentable model. Kotlin and Java sources are supported by default, but you can analyze any language as long as you can map it to the Documentable model. For reference, see DefaultDescriptorToDocumentableTranslator for Kotlin sources translation DefaultPsiToDocumentableTranslator for Java sources translation PreMergeDocumentableTransformer \u00b6 This extension point actually comes from DokkaBase and is not a core extension point, but it's used in SingleModuleGeneration nonetheless. If you are implementing your own plugin without relying on DokkaBase , you can either introduce a similar extension point or rely on DocumentableTransformer which will be discussed below. PreMergeDocumentableTransformer allows applying any transformation to Documentables model before different source sets are merged. Useful if you want to filter/map existing documentables. For instance, if you want to exclude members annotated with @Internal , you most likely need an implementation of PreMergeDocumentableTransformer . For simple condition-based filtering of documentables consider extending SuppressedByConditionDocumentableFilterTransformer - it implements PreMergeDocumentableTransformer and only requires one function to be overridden. The rest is taken care of. DocumentableMerger \u00b6 DocumentableMerger merges all DModule instances into one. Only one extension is expected of this type. DocumentableTransformer \u00b6 DocumentableTransformer performs the same function as PreMergeDocumentableTransformer , but after merging source sets. Notable example is InheritorsExtractorTransformer , it extracts inherited classes data across source sets and creates an inheritance map. DocumentableToPageTranslator \u00b6 DocumentableToPageTranslator is responsible for creating pages and their content. See Page/Content model section for more information and examples. Different output formats can either use the same page structure or define their own in case it needs to be different. Only a single extension of this type is expected to be registered. PageTransformer \u00b6 PageTransformer is useful if you need to add/remove/modify generated pages or their content. Plugins like mathjax can add .js scripts to pages using this extension point. If you want all overloaded functions to be rendered on the same page (instead of separate ones), you can also use PageTransformer to delete excessive pages and combine them into a new single one. Renderer \u00b6 Renderer - defines rules on what to do with pages and their content, which files to create and how to display it properly. Output format implementations should use Renderer extension point. Notable examples are HtmlRenderer and CommonmarkRenderer . PostAction \u00b6 PostAction is useful for when you want to run some actions after the documentation has been generated - for instance if you want to move some files around. Versioning plugin utilizes PostAction in order to move generated documentation to versioned folders.","title":"Core extension points"},{"location":"developer_guide/architecture/extension_points/core_extensions/#core-extension-points","text":"Core extension points represent the main stages of generating documentation. These extension points are plugin and output format independent, meaning it's the very core functionality and as low-level as can get. For higher-level extension functions that can be used in different output formats, have a look at Base extensions defined in DokkaBase . You can find all core extensions in CoreExtensions class: object CoreExtensions { val preGenerationCheck by coreExtensionPoint < PreGenerationChecker > () val generation by coreExtensionPoint < Generation > () val sourceToDocumentableTranslator by coreExtensionPoint < SourceToDocumentableTranslator > () val documentableMerger by coreExtensionPoint < DocumentableMerger > () val documentableTransformer by coreExtensionPoint < DocumentableTransformer > () val documentableToPageTranslator by coreExtensionPoint < DocumentableToPageTranslator > () val pageTransformer by coreExtensionPoint < PageTransformer > () val renderer by coreExtensionPoint < Renderer > () val postActions by coreExtensionPoint < PostAction > () } On this page we'll go over each extension point individually.","title":"Core extension points"},{"location":"developer_guide/architecture/extension_points/core_extensions/#pregenerationchecker","text":"PreGenerationChecker can be used to run some checks and constraints. For instance, Javadoc plugin does not support generating documentation for multi-platform projects, so it uses PreGenerationChecker to check for multi-platform source sets and fails if it finds any.","title":"PreGenerationChecker"},{"location":"developer_guide/architecture/extension_points/core_extensions/#generation","text":"Generation is responsible for generating documentation as a whole, utilizing other extension points where applicable. There are two implementations at the moment: AllModulesPageGeneration - generates multimodule documentation, for instance when dokkaHtmlMultiModule task is invoked. SingleModuleGeneration - generates documentation for a single module, for instance when dokkaHtml task is invoked","title":"Generation"},{"location":"developer_guide/architecture/extension_points/core_extensions/#allmodulespagegeneration","text":"AllModulesPageGeneration utilizes output generated by SingleModuleGeneration . Under the hood it just collects all pages generated for individual modules and assembles everything together, creating navigation pages between the modules and so on.","title":"AllModulesPageGeneration"},{"location":"developer_guide/architecture/extension_points/core_extensions/#singlemodulegeneration-stages","text":"When developing a feature or a plugin, it's more convenient to think that you are generating documentation for single module projects, believing that Dokka will somehow take care of the rest in multimodule environment. SingleModuleGeneration is at heart of generating documentation and utilizes other core extension points, so it's worth going over its stages. Below you can see the transformations of Dokka's models and extension interfaces responsible for each one. Notice how Documentables and Pages are transformed multiple times. flowchart TD Input -- SourceToDocumentableTranslator --> doc1[Documentables] subgraph documentables [ ] doc1 -- PreMergeDocumentableTransformer --> doc2[Documentables] doc2 -- DocumentableMerger --> doc3[Documentables] doc3 -- DocumentableTransformer --> doc4[Documentables] end doc4 -- DocumentableToPageTranslator --> page1[Pages] subgraph ide2 [ ] page1 -- PageTransformer --> page2[Pages] end page2 -- Renderer --> Output","title":"SingleModuleGeneration stages"},{"location":"developer_guide/architecture/extension_points/core_extensions/#sourcetodocumentabletranslator","text":"SourceToDocumentableTranslator translates sources into documentable model. Kotlin and Java sources are supported by default, but you can analyze any language as long as you can map it to the Documentable model. For reference, see DefaultDescriptorToDocumentableTranslator for Kotlin sources translation DefaultPsiToDocumentableTranslator for Java sources translation","title":"SourceToDocumentableTranslator"},{"location":"developer_guide/architecture/extension_points/core_extensions/#premergedocumentabletransformer","text":"This extension point actually comes from DokkaBase and is not a core extension point, but it's used in SingleModuleGeneration nonetheless. If you are implementing your own plugin without relying on DokkaBase , you can either introduce a similar extension point or rely on DocumentableTransformer which will be discussed below. PreMergeDocumentableTransformer allows applying any transformation to Documentables model before different source sets are merged. Useful if you want to filter/map existing documentables. For instance, if you want to exclude members annotated with @Internal , you most likely need an implementation of PreMergeDocumentableTransformer . For simple condition-based filtering of documentables consider extending SuppressedByConditionDocumentableFilterTransformer - it implements PreMergeDocumentableTransformer and only requires one function to be overridden. The rest is taken care of.","title":"PreMergeDocumentableTransformer"},{"location":"developer_guide/architecture/extension_points/core_extensions/#documentablemerger","text":"DocumentableMerger merges all DModule instances into one. Only one extension is expected of this type.","title":"DocumentableMerger"},{"location":"developer_guide/architecture/extension_points/core_extensions/#documentabletransformer","text":"DocumentableTransformer performs the same function as PreMergeDocumentableTransformer , but after merging source sets. Notable example is InheritorsExtractorTransformer , it extracts inherited classes data across source sets and creates an inheritance map.","title":"DocumentableTransformer"},{"location":"developer_guide/architecture/extension_points/core_extensions/#documentabletopagetranslator","text":"DocumentableToPageTranslator is responsible for creating pages and their content. See Page/Content model section for more information and examples. Different output formats can either use the same page structure or define their own in case it needs to be different. Only a single extension of this type is expected to be registered.","title":"DocumentableToPageTranslator"},{"location":"developer_guide/architecture/extension_points/core_extensions/#pagetransformer","text":"PageTransformer is useful if you need to add/remove/modify generated pages or their content. Plugins like mathjax can add .js scripts to pages using this extension point. If you want all overloaded functions to be rendered on the same page (instead of separate ones), you can also use PageTransformer to delete excessive pages and combine them into a new single one.","title":"PageTransformer"},{"location":"developer_guide/architecture/extension_points/core_extensions/#renderer","text":"Renderer - defines rules on what to do with pages and their content, which files to create and how to display it properly. Output format implementations should use Renderer extension point. Notable examples are HtmlRenderer and CommonmarkRenderer .","title":"Renderer"},{"location":"developer_guide/architecture/extension_points/core_extensions/#postaction","text":"PostAction is useful for when you want to run some actions after the documentation has been generated - for instance if you want to move some files around. Versioning plugin utilizes PostAction in order to move generated documentation to versioned folders.","title":"PostAction"},{"location":"developer_guide/architecture/extension_points/introduction/","text":"Introduction to extension points \u00b6 In this section you can learn how to create new extension points, how to use and configure existing ones and how to query for extensions when generating documentation. Declaring extension points \u00b6 If you are writing a plugin, you can create your own extension point that other developers (or you) can use later on in some other part of code. class MyPlugin : DokkaPlugin () { val sampleExtensionPoint by extensionPoint < SampleExtensionPointInterface > () } interface SampleExtensionPointInterface { fun doSomething ( input : Input ): List < Output > } class Input class Output Usually you would want to provide some default implementation(s) for your extension point, you can do that within the same plugin class by extending an extension point you've just created. See Extending from extension points for examples. Extending from extension points \u00b6 You can use extension points to provide your own implementation(s) in order to customize plugin's behaviour. You can do that within the same class as the extension point itself: open class MyPlugin : DokkaPlugin () { val sampleExtensionPoint by extensionPoint < SampleExtensionPointInterface > () val defaultSampleExtension by extending { sampleExtensionPoint with DefaultSampleExtension () } } ... class DefaultSampleExtension : SampleExtensionPointInterface { override fun doSomething ( input : Input ): List < Output > = listOf () } If you want to extend someone else's plugin (including DokkaBase ), you can use plugin querying API to do that. In the example below we will extend MyPlugin that was created above with our own implementation of SampleExtensionPointInterface . class MyExtendedPlugin : DokkaPlugin () { val mySampleExtensionImplementation by extending { plugin < MyPlugin > (). sampleExtensionPoint with SampleExtensionImpl () } } class SampleExtensionImpl : SampleExtensionPointInterface { override fun doSomething ( input : Input ): List < Output > = listOf () } Providing \u00b6 If you need to have access to DokkaContext in order to create an extension, you can use providing instead. val defaultSampleExtension by extending { sampleExtensionPoint providing { context -> // can use context to query other extensions or get configuration DefaultSampleExtension () } } You can read more on what you can do with context in Obtaining extension instance . Override \u00b6 By extending an extension point, you are registering an additional extension. This behaviour is expected for some extension points, for instance Documentable transformers, since all transformers do their own transformations and all of them will be invoked before proceeding. However, a plugin can expect only a single registered extension for an extension point. In this case, you can override existing registered extensions: class MyExtendedPlugin : DokkaPlugin () { private val myPlugin by lazy { plugin < MyPlugin > () } val mySampleExtensionImplementation by extending { ( myPlugin . sampleExtensionPoint with SampleExtensionImpl () override myPlugin . defaultSampleExtension ) } } This is also useful if you wish to override some extension from DokkaBase to disable or alter it. Order \u00b6 Sometimes the order in which extensions are invoked matters. This is something you can control as well using order : class MyExtendedPlugin : DokkaPlugin () { private val myPlugin by lazy { plugin < MyPlugin > () } val mySampleExtensionImplementation by extending { myPlugin . sampleExtensionPoint with SampleExtensionImpl () order { before ( myPlugin . firstExtension ) after ( myPlugin . thirdExtension ) } } } Conditional apply \u00b6 If you want your extension to be registered only if some condition is true , you can use applyIf : class MyExtendedPlugin : DokkaPlugin () { private val myPlugin by lazy { plugin < MyPlugin > () } val mySampleExtensionImplementation by extending { myPlugin . sampleExtensionPoint with SampleExtensionImpl () applyIf { Random . Default . nextBoolean () } } } Obtaining extension instance \u00b6 After an extension point has been created and some extension has been registered , you can use query and querySingle to find all or just a single implementation for it. class MyExtension ( context : DokkaContext ) { // returns all registered extensions for this extension point val allSampleExtensions = context . plugin < MyPlugin > (). query { sampleExtensionPoint } // will throw an exception if more than one extension is found // use if you expect only a single extension to be registered for this extension point val singleSampleExtensions = context . plugin < MyPlugin > (). querySingle { sampleExtensionPoint } fun invoke () { allSampleExtensions . forEach { it . doSomething ( Input ()) } singleSampleExtensions . doSomething ( Input ()) } } In order to have access to context you can use providing when registering this as an extension.","title":"Extension points"},{"location":"developer_guide/architecture/extension_points/introduction/#introduction-to-extension-points","text":"In this section you can learn how to create new extension points, how to use and configure existing ones and how to query for extensions when generating documentation.","title":"Introduction to extension points"},{"location":"developer_guide/architecture/extension_points/introduction/#declaring-extension-points","text":"If you are writing a plugin, you can create your own extension point that other developers (or you) can use later on in some other part of code. class MyPlugin : DokkaPlugin () { val sampleExtensionPoint by extensionPoint < SampleExtensionPointInterface > () } interface SampleExtensionPointInterface { fun doSomething ( input : Input ): List < Output > } class Input class Output Usually you would want to provide some default implementation(s) for your extension point, you can do that within the same plugin class by extending an extension point you've just created. See Extending from extension points for examples.","title":"Declaring extension points"},{"location":"developer_guide/architecture/extension_points/introduction/#extending-from-extension-points","text":"You can use extension points to provide your own implementation(s) in order to customize plugin's behaviour. You can do that within the same class as the extension point itself: open class MyPlugin : DokkaPlugin () { val sampleExtensionPoint by extensionPoint < SampleExtensionPointInterface > () val defaultSampleExtension by extending { sampleExtensionPoint with DefaultSampleExtension () } } ... class DefaultSampleExtension : SampleExtensionPointInterface { override fun doSomething ( input : Input ): List < Output > = listOf () } If you want to extend someone else's plugin (including DokkaBase ), you can use plugin querying API to do that. In the example below we will extend MyPlugin that was created above with our own implementation of SampleExtensionPointInterface . class MyExtendedPlugin : DokkaPlugin () { val mySampleExtensionImplementation by extending { plugin < MyPlugin > (). sampleExtensionPoint with SampleExtensionImpl () } } class SampleExtensionImpl : SampleExtensionPointInterface { override fun doSomething ( input : Input ): List < Output > = listOf () }","title":"Extending from extension points"},{"location":"developer_guide/architecture/extension_points/introduction/#providing","text":"If you need to have access to DokkaContext in order to create an extension, you can use providing instead. val defaultSampleExtension by extending { sampleExtensionPoint providing { context -> // can use context to query other extensions or get configuration DefaultSampleExtension () } } You can read more on what you can do with context in Obtaining extension instance .","title":"Providing"},{"location":"developer_guide/architecture/extension_points/introduction/#override","text":"By extending an extension point, you are registering an additional extension. This behaviour is expected for some extension points, for instance Documentable transformers, since all transformers do their own transformations and all of them will be invoked before proceeding. However, a plugin can expect only a single registered extension for an extension point. In this case, you can override existing registered extensions: class MyExtendedPlugin : DokkaPlugin () { private val myPlugin by lazy { plugin < MyPlugin > () } val mySampleExtensionImplementation by extending { ( myPlugin . sampleExtensionPoint with SampleExtensionImpl () override myPlugin . defaultSampleExtension ) } } This is also useful if you wish to override some extension from DokkaBase to disable or alter it.","title":"Override"},{"location":"developer_guide/architecture/extension_points/introduction/#order","text":"Sometimes the order in which extensions are invoked matters. This is something you can control as well using order : class MyExtendedPlugin : DokkaPlugin () { private val myPlugin by lazy { plugin < MyPlugin > () } val mySampleExtensionImplementation by extending { myPlugin . sampleExtensionPoint with SampleExtensionImpl () order { before ( myPlugin . firstExtension ) after ( myPlugin . thirdExtension ) } } }","title":"Order"},{"location":"developer_guide/architecture/extension_points/introduction/#conditional-apply","text":"If you want your extension to be registered only if some condition is true , you can use applyIf : class MyExtendedPlugin : DokkaPlugin () { private val myPlugin by lazy { plugin < MyPlugin > () } val mySampleExtensionImplementation by extending { myPlugin . sampleExtensionPoint with SampleExtensionImpl () applyIf { Random . Default . nextBoolean () } } }","title":"Conditional apply"},{"location":"developer_guide/architecture/extension_points/introduction/#obtaining-extension-instance","text":"After an extension point has been created and some extension has been registered , you can use query and querySingle to find all or just a single implementation for it. class MyExtension ( context : DokkaContext ) { // returns all registered extensions for this extension point val allSampleExtensions = context . plugin < MyPlugin > (). query { sampleExtensionPoint } // will throw an exception if more than one extension is found // use if you expect only a single extension to be registered for this extension point val singleSampleExtensions = context . plugin < MyPlugin > (). querySingle { sampleExtensionPoint } fun invoke () { allSampleExtensions . forEach { it . doSomething ( Input ()) } singleSampleExtensions . doSomething ( Input ()) } } In order to have access to context you can use providing when registering this as an extension.","title":"Obtaining extension instance"},{"location":"developer_guide/plugin-development/introduction/","text":"Introduction to plugin development \u00b6 Dokka was built from the ground up to be easily extensible and highly customizable, which allows the community to implement plugins for missing or very specific features that are not provided out of the box. Dokka plugins range anywhere from supporting other programming language sources to exotic output formats. You can add support for your own KDoc tags or annotations, teach Dokka how to render different DSLs that are found in KDoc descriptions, visually redesign Dokka's pages to be seamlessly integrated into your company's website, integrate it with other tools and so much more. In order to have an easier time developing plugins, it's a good idea to go through Dokka's internals first to learn more about its data model and extensions . Setup \u00b6 Template \u00b6 The easiest way to start is to use the convenient Dokka plugin template . It has pre-configured dependencies, publishing and signing of your artifacts. Manual \u00b6 At a bare minimum, Dokka requires Kotlin Gradle Plugin and dokka-core dependencies: import org.jetbrains.kotlin.gradle.dsl.JvmTarget import org.jetbrains.kotlin.gradle.tasks.KotlinCompile plugins { kotlin ( \"jvm\" ) version \"<kotlin_version>\" } dependencies { compileOnly ( \"org.jetbrains.dokka:dokka-core:<dokka_version>\" ) } tasks . withType < KotlinCompile > (). configureEach { compilerOptions . jvmTarget . set ( JvmTarget . JVM_1_8 ) } In order to load a plugin into Dokka, your class must extend DokkaPlugin class. A fully qualified name of that class must be placed in a file named org.jetbrains.dokka.plugability.DokkaPlugin under resources/META-INF/services . All instances are automatically loaded during Dokka setup using java.util.ServiceLoader . Extension points \u00b6 Dokka provides a set of entry points for which you can create your own implementations. If you are not sure which extension point to use, have a look at core extensions and base extensions . You can learn how to declare extension points and use extensions in Introduction to Extension points . In case no suitable extension point exists for your use case, do share the details - it might be added in future versions of Dokka. Example \u00b6 You can follow the sample plugin tutorial which covers creation of a simple plugin: hide members annotated with your own @Internal annotation, that is exclude these members from generated documentation. Fore more practical examples, have a look at sources of community plugins . Help \u00b6 If you have any further questions, feel free to get in touch with maintainers via Slack or GitHub .","title":"Plugin development"},{"location":"developer_guide/plugin-development/introduction/#introduction-to-plugin-development","text":"Dokka was built from the ground up to be easily extensible and highly customizable, which allows the community to implement plugins for missing or very specific features that are not provided out of the box. Dokka plugins range anywhere from supporting other programming language sources to exotic output formats. You can add support for your own KDoc tags or annotations, teach Dokka how to render different DSLs that are found in KDoc descriptions, visually redesign Dokka's pages to be seamlessly integrated into your company's website, integrate it with other tools and so much more. In order to have an easier time developing plugins, it's a good idea to go through Dokka's internals first to learn more about its data model and extensions .","title":"Introduction to plugin development"},{"location":"developer_guide/plugin-development/introduction/#setup","text":"","title":"Setup"},{"location":"developer_guide/plugin-development/introduction/#template","text":"The easiest way to start is to use the convenient Dokka plugin template . It has pre-configured dependencies, publishing and signing of your artifacts.","title":"Template"},{"location":"developer_guide/plugin-development/introduction/#manual","text":"At a bare minimum, Dokka requires Kotlin Gradle Plugin and dokka-core dependencies: import org.jetbrains.kotlin.gradle.dsl.JvmTarget import org.jetbrains.kotlin.gradle.tasks.KotlinCompile plugins { kotlin ( \"jvm\" ) version \"<kotlin_version>\" } dependencies { compileOnly ( \"org.jetbrains.dokka:dokka-core:<dokka_version>\" ) } tasks . withType < KotlinCompile > (). configureEach { compilerOptions . jvmTarget . set ( JvmTarget . JVM_1_8 ) } In order to load a plugin into Dokka, your class must extend DokkaPlugin class. A fully qualified name of that class must be placed in a file named org.jetbrains.dokka.plugability.DokkaPlugin under resources/META-INF/services . All instances are automatically loaded during Dokka setup using java.util.ServiceLoader .","title":"Manual"},{"location":"developer_guide/plugin-development/introduction/#extension-points","text":"Dokka provides a set of entry points for which you can create your own implementations. If you are not sure which extension point to use, have a look at core extensions and base extensions . You can learn how to declare extension points and use extensions in Introduction to Extension points . In case no suitable extension point exists for your use case, do share the details - it might be added in future versions of Dokka.","title":"Extension points"},{"location":"developer_guide/plugin-development/introduction/#example","text":"You can follow the sample plugin tutorial which covers creation of a simple plugin: hide members annotated with your own @Internal annotation, that is exclude these members from generated documentation. Fore more practical examples, have a look at sources of community plugins .","title":"Example"},{"location":"developer_guide/plugin-development/introduction/#help","text":"If you have any further questions, feel free to get in touch with maintainers via Slack or GitHub .","title":"Help"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/","text":"Sample plugin tutorial \u00b6 We'll go over creating a simple plugin that covers a very common use case: generate documentation for everything except for members annotated with a custom @Internal annotation - they should be hidden. The plugin will be tested with the following code: package org.jetbrains.dokka.internal.test annotation class Internal fun shouldBeVisible () {} @Internal fun shouldBeExcludedFromDocumentation () {} Expected behavior: function shouldBeExcludedFromDocumentation should not be visible in generated documentation. Full source code of this tutorial can be found in Dokka's examples under hide-internal-api . Preparing the project \u00b6 We'll begin by using Dokka plugin template . Press the Use this template button and open this project in IntelliJ IDEA . First, let's rename the pre-made template package and MyAwesomeDokkaPlugin class to something of our own. For instance, package can be renamed to org.example.dokka.plugin and the class to HideInternalApiPlugin : package org.example.dokka.plugin import org.jetbrains.dokka.plugability.DokkaPlugin class HideInternalApiPlugin : DokkaPlugin () { } After you do that, make sure to update the path to this class in resources/META-INF/services/org.jetbrains.dokka.plugability.DokkaPlugin : org . example . dokka . plugin . HideInternalApiPlugin At this point you can also change project name in settings.gradle.kts (to hide-internal-api in our case) and groupId in build.gradle.kts . Extending Dokka \u00b6 After preparing the project we can begin extending Dokka with our own extension. Having read through Core extensions , it's clear that we need a PreMergeDocumentableTransformer extension in order to filter out undesired documentables. Moreover, the article mentioned a convenient abstract transformer SuppressedByConditionDocumentableFilterTransformer which is perfect for our use case, so we can try to implement it. Create a new class, place it next to your plugin and implement the abstract method. You should end up with this: package org.example.dokka.plugin import org.jetbrains.dokka.base.transformers.documentables.SuppressedByConditionDocumentableFilterTransformer import org.jetbrains.dokka.model.Documentable import org.jetbrains.dokka.plugability.DokkaContext import org.jetbrains.dokka.plugability.DokkaPlugin class HideInternalApiPlugin : DokkaPlugin () {} class HideInternalApiTransformer ( context : DokkaContext ) : SuppressedByConditionDocumentableFilterTransformer ( context ) { override fun shouldBeSuppressed ( d : Documentable ): Boolean { return false } } Now we somehow need to find all annotations applied to d: Documentable and see if our @Internal annotation is present. However, it's not very clear how to do that. What usually helps is stopping in debugger and having a look at what fields and values a given Documentable has. To do that, we'll need to register our extension point first, then we can publish our plugin and set the breakpoint. Having read through Introduction to extensions , we now know how to register our extensions: class HideInternalApiPlugin : DokkaPlugin () { val myFilterExtension by extending { plugin < DokkaBase > (). preMergeDocumentableTransformer providing :: HideInternalApiTransformer } } At this point we're ready to debug our plugin locally, it should already work, but do nothing. Debugging \u00b6 Please read through Debugging Dokka , it goes over the same steps in more detail and with examples. Below you will find rough instructions. First, let's begin by publishing our plugin to mavenLocal() . ./gradlew publishToMavenLocal This will publish your plugin under the groupId , artifactId and version that you've specified in your build.gradle.kts . In our case it's org.example:hide-internal-api:1.0-SNAPSHOT . Open a debug project of your choosing that has Dokka configured, and add our plugin to dependencies: dependencies { dokkaPlugin ( \"org.example:hide-internal-api:1.0-SNAPSHOT\" ) } Next, in that project let's run dokkaHtml with debug enabled: ./gradlew clean dokkaHtml -Dorg.gradle.debug = true --no-daemon Switch to the plugin project, set a breakpoint inside shouldBeSuppressed and run jvm remote debug. If you've done everything correctly, it should stop in debugger and you should be able to observe the values contained inside d: Documentable . Implementing plugin logic \u00b6 Now that we've stopped at our breakpoint, let's skip until we see shouldBeExcludedFromDocumentation function in the place of d: Documentable (observe the changing name property). Looking at what's inside the object, you might notice it has 3 values in extra , one of which is Annotations . Sounds like something we need! Having poked around, we come up with the following monstrosity of a code for determining if a given documentable has @Internal annotation (it can of course be refactored.. later): override fun shouldBeSuppressed ( d : Documentable ): Boolean { val annotations : List < Annotations . Annotation > = ( d as? WithExtraProperties <*> ) ?. extra ?. allOfType < Annotations > () ?. flatMap { it . directAnnotations . values . flatten () } ?: emptyList () return annotations . any { isInternalAnnotation ( it ) } } private fun isInternalAnnotation ( annotation : Annotations . Annotation ): Boolean { return annotation . dri . packageName == \"org.jetbrains.dokka.internal.test\" && annotation . dri . classNames == \"Internal\" } Seems like we're done with writing our plugin and can begin testing it manually. Manual testing \u00b6 At this point, the implementation of your plugin should look roughly like this: package org.example.dokka.plugin import org.jetbrains.dokka.base.DokkaBase import org.jetbrains.dokka.base.transformers.documentables.SuppressedByConditionDocumentableFilterTransformer import org.jetbrains.dokka.model.Annotations import org.jetbrains.dokka.model.Documentable import org.jetbrains.dokka.model.properties.WithExtraProperties import org.jetbrains.dokka.plugability.DokkaContext import org.jetbrains.dokka.plugability.DokkaPlugin class HideInternalApiPlugin : DokkaPlugin () { val myFilterExtension by extending { plugin < DokkaBase > (). preMergeDocumentableTransformer providing :: HideInternalApiTransformer } } class HideInternalApiTransformer ( context : DokkaContext ) : SuppressedByConditionDocumentableFilterTransformer ( context ) { override fun shouldBeSuppressed ( d : Documentable ): Boolean { val annotations : List < Annotations . Annotation > = ( d as? WithExtraProperties <*> ) ?. extra ?. allOfType < Annotations > () ?. flatMap { it . directAnnotations . values . flatten () } ?: emptyList () return annotations . any { isInternalAnnotation ( it ) } } private fun isInternalAnnotation ( annotation : Annotations . Annotation ): Boolean { return annotation . dri . packageName == \"org.jetbrains.dokka.internal.test\" && annotation . dri . classNames == \"Internal\" } } Bump plugin version in gradle.build.kts , publish it to maven local, open the debug project and run dokkaHtml (without debug this time). It should work, you should not be able to see shouldBeExcludedFromDocumentation function in generated documentation. Manual testing is cool and all, but wouldn't it be better if we could somehow write unit tests for it? Indeed! Unit testing \u00b6 You might've noticed that plugin template comes with a pre-made test class. Feel free to move it to another package and rename it. We are mostly interested in a single test case - functions annotated with @Internal should be hidden, while all other public functions should be visible. Plugin API comes with a set of convenient test utilities that are used to test Dokka itself, so it covers a wide range of use cases. When in doubt, see Dokka's tests for reference. Below you will find a complete unit test that passes, and the main takeaways below that. package org.example.dokka.plugin import org.jetbrains.dokka.base.testApi.testRunner.BaseAbstractTest import org.junit.Test import kotlin.test.assertEquals class HideInternalApiPluginTest : BaseAbstractTest () { @Test fun `should hide annotated functions` () { val configuration = dokkaConfiguration { sourceSets { sourceSet { sourceRoots = listOf ( \"src/main/kotlin/basic/Test.kt\" ) } } } val hideInternalPlugin = HideInternalApiPlugin () testInline ( \"\"\" |/src/main/kotlin/basic/Test.kt |package org.jetbrains.dokka.internal.test | |annotation class Internal | |fun shouldBeVisible() {} | |@Internal |fun shouldBeExcludedFromDocumentation() {} \"\"\" . trimMargin (), configuration = configuration , pluginOverrides = listOf ( hideInternalPlugin ) ) { preMergeDocumentablesTransformationStage = { modules -> val testModule = modules . single { it . name == \"root\" } val testPackage = testModule . packages . single { it . name == \"org.jetbrains.dokka.internal.test\" } val packageFunctions = testPackage . functions assertEquals ( 1 , packageFunctions . size ) assertEquals ( \"shouldBeVisible\" , packageFunctions [ 0 ] . name ) } } } } Note that the package of the tested code (inside testInline function) is the same as the package that we have hardcoded in our plugin. Make sure to change that to your own if you are following along, otherwise it will fail. Things to note and remember: Your test class should extend BaseAbstractTest , which contains base utility methods for testing. You can configure Dokka to your liking, enable some specific settings, configure source sets , etc. All done via dokkaConfiguration DSL. testInline function is the main entry point for unit tests You can pass plugins to be used in a test, notice pluginOverrides parameter You can write asserts for different stages of generating documentation, the main ones being Documentables model generation, Pages generation and Output generation. Since we implemented our plugin to work during PreMergeDocumentableTransformer stage, we can test it on the same level (that is preMergeDocumentablesTransformationStage ). You will need to write asserts using the model of whatever stage you choose. For Documentable transformation stage it's Documentable , for Page generation stage you would have Page model, and for Output you can have .html files that you will need to parse with JSoup (there are also utilities for that). Full source code of this tutorial can be found in Dokka's examples under hide-internal-api .","title":"Sample plugin tutorial"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#sample-plugin-tutorial","text":"We'll go over creating a simple plugin that covers a very common use case: generate documentation for everything except for members annotated with a custom @Internal annotation - they should be hidden. The plugin will be tested with the following code: package org.jetbrains.dokka.internal.test annotation class Internal fun shouldBeVisible () {} @Internal fun shouldBeExcludedFromDocumentation () {} Expected behavior: function shouldBeExcludedFromDocumentation should not be visible in generated documentation. Full source code of this tutorial can be found in Dokka's examples under hide-internal-api .","title":"Sample plugin tutorial"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#preparing-the-project","text":"We'll begin by using Dokka plugin template . Press the Use this template button and open this project in IntelliJ IDEA . First, let's rename the pre-made template package and MyAwesomeDokkaPlugin class to something of our own. For instance, package can be renamed to org.example.dokka.plugin and the class to HideInternalApiPlugin : package org.example.dokka.plugin import org.jetbrains.dokka.plugability.DokkaPlugin class HideInternalApiPlugin : DokkaPlugin () { } After you do that, make sure to update the path to this class in resources/META-INF/services/org.jetbrains.dokka.plugability.DokkaPlugin : org . example . dokka . plugin . HideInternalApiPlugin At this point you can also change project name in settings.gradle.kts (to hide-internal-api in our case) and groupId in build.gradle.kts .","title":"Preparing the project"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#extending-dokka","text":"After preparing the project we can begin extending Dokka with our own extension. Having read through Core extensions , it's clear that we need a PreMergeDocumentableTransformer extension in order to filter out undesired documentables. Moreover, the article mentioned a convenient abstract transformer SuppressedByConditionDocumentableFilterTransformer which is perfect for our use case, so we can try to implement it. Create a new class, place it next to your plugin and implement the abstract method. You should end up with this: package org.example.dokka.plugin import org.jetbrains.dokka.base.transformers.documentables.SuppressedByConditionDocumentableFilterTransformer import org.jetbrains.dokka.model.Documentable import org.jetbrains.dokka.plugability.DokkaContext import org.jetbrains.dokka.plugability.DokkaPlugin class HideInternalApiPlugin : DokkaPlugin () {} class HideInternalApiTransformer ( context : DokkaContext ) : SuppressedByConditionDocumentableFilterTransformer ( context ) { override fun shouldBeSuppressed ( d : Documentable ): Boolean { return false } } Now we somehow need to find all annotations applied to d: Documentable and see if our @Internal annotation is present. However, it's not very clear how to do that. What usually helps is stopping in debugger and having a look at what fields and values a given Documentable has. To do that, we'll need to register our extension point first, then we can publish our plugin and set the breakpoint. Having read through Introduction to extensions , we now know how to register our extensions: class HideInternalApiPlugin : DokkaPlugin () { val myFilterExtension by extending { plugin < DokkaBase > (). preMergeDocumentableTransformer providing :: HideInternalApiTransformer } } At this point we're ready to debug our plugin locally, it should already work, but do nothing.","title":"Extending Dokka"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#debugging","text":"Please read through Debugging Dokka , it goes over the same steps in more detail and with examples. Below you will find rough instructions. First, let's begin by publishing our plugin to mavenLocal() . ./gradlew publishToMavenLocal This will publish your plugin under the groupId , artifactId and version that you've specified in your build.gradle.kts . In our case it's org.example:hide-internal-api:1.0-SNAPSHOT . Open a debug project of your choosing that has Dokka configured, and add our plugin to dependencies: dependencies { dokkaPlugin ( \"org.example:hide-internal-api:1.0-SNAPSHOT\" ) } Next, in that project let's run dokkaHtml with debug enabled: ./gradlew clean dokkaHtml -Dorg.gradle.debug = true --no-daemon Switch to the plugin project, set a breakpoint inside shouldBeSuppressed and run jvm remote debug. If you've done everything correctly, it should stop in debugger and you should be able to observe the values contained inside d: Documentable .","title":"Debugging"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#implementing-plugin-logic","text":"Now that we've stopped at our breakpoint, let's skip until we see shouldBeExcludedFromDocumentation function in the place of d: Documentable (observe the changing name property). Looking at what's inside the object, you might notice it has 3 values in extra , one of which is Annotations . Sounds like something we need! Having poked around, we come up with the following monstrosity of a code for determining if a given documentable has @Internal annotation (it can of course be refactored.. later): override fun shouldBeSuppressed ( d : Documentable ): Boolean { val annotations : List < Annotations . Annotation > = ( d as? WithExtraProperties <*> ) ?. extra ?. allOfType < Annotations > () ?. flatMap { it . directAnnotations . values . flatten () } ?: emptyList () return annotations . any { isInternalAnnotation ( it ) } } private fun isInternalAnnotation ( annotation : Annotations . Annotation ): Boolean { return annotation . dri . packageName == \"org.jetbrains.dokka.internal.test\" && annotation . dri . classNames == \"Internal\" } Seems like we're done with writing our plugin and can begin testing it manually.","title":"Implementing plugin logic"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#manual-testing","text":"At this point, the implementation of your plugin should look roughly like this: package org.example.dokka.plugin import org.jetbrains.dokka.base.DokkaBase import org.jetbrains.dokka.base.transformers.documentables.SuppressedByConditionDocumentableFilterTransformer import org.jetbrains.dokka.model.Annotations import org.jetbrains.dokka.model.Documentable import org.jetbrains.dokka.model.properties.WithExtraProperties import org.jetbrains.dokka.plugability.DokkaContext import org.jetbrains.dokka.plugability.DokkaPlugin class HideInternalApiPlugin : DokkaPlugin () { val myFilterExtension by extending { plugin < DokkaBase > (). preMergeDocumentableTransformer providing :: HideInternalApiTransformer } } class HideInternalApiTransformer ( context : DokkaContext ) : SuppressedByConditionDocumentableFilterTransformer ( context ) { override fun shouldBeSuppressed ( d : Documentable ): Boolean { val annotations : List < Annotations . Annotation > = ( d as? WithExtraProperties <*> ) ?. extra ?. allOfType < Annotations > () ?. flatMap { it . directAnnotations . values . flatten () } ?: emptyList () return annotations . any { isInternalAnnotation ( it ) } } private fun isInternalAnnotation ( annotation : Annotations . Annotation ): Boolean { return annotation . dri . packageName == \"org.jetbrains.dokka.internal.test\" && annotation . dri . classNames == \"Internal\" } } Bump plugin version in gradle.build.kts , publish it to maven local, open the debug project and run dokkaHtml (without debug this time). It should work, you should not be able to see shouldBeExcludedFromDocumentation function in generated documentation. Manual testing is cool and all, but wouldn't it be better if we could somehow write unit tests for it? Indeed!","title":"Manual testing"},{"location":"developer_guide/plugin-development/sample-plugin-tutorial/#unit-testing","text":"You might've noticed that plugin template comes with a pre-made test class. Feel free to move it to another package and rename it. We are mostly interested in a single test case - functions annotated with @Internal should be hidden, while all other public functions should be visible. Plugin API comes with a set of convenient test utilities that are used to test Dokka itself, so it covers a wide range of use cases. When in doubt, see Dokka's tests for reference. Below you will find a complete unit test that passes, and the main takeaways below that. package org.example.dokka.plugin import org.jetbrains.dokka.base.testApi.testRunner.BaseAbstractTest import org.junit.Test import kotlin.test.assertEquals class HideInternalApiPluginTest : BaseAbstractTest () { @Test fun `should hide annotated functions` () { val configuration = dokkaConfiguration { sourceSets { sourceSet { sourceRoots = listOf ( \"src/main/kotlin/basic/Test.kt\" ) } } } val hideInternalPlugin = HideInternalApiPlugin () testInline ( \"\"\" |/src/main/kotlin/basic/Test.kt |package org.jetbrains.dokka.internal.test | |annotation class Internal | |fun shouldBeVisible() {} | |@Internal |fun shouldBeExcludedFromDocumentation() {} \"\"\" . trimMargin (), configuration = configuration , pluginOverrides = listOf ( hideInternalPlugin ) ) { preMergeDocumentablesTransformationStage = { modules -> val testModule = modules . single { it . name == \"root\" } val testPackage = testModule . packages . single { it . name == \"org.jetbrains.dokka.internal.test\" } val packageFunctions = testPackage . functions assertEquals ( 1 , packageFunctions . size ) assertEquals ( \"shouldBeVisible\" , packageFunctions [ 0 ] . name ) } } } } Note that the package of the tested code (inside testInline function) is the same as the package that we have hardcoded in our plugin. Make sure to change that to your own if you are following along, otherwise it will fail. Things to note and remember: Your test class should extend BaseAbstractTest , which contains base utility methods for testing. You can configure Dokka to your liking, enable some specific settings, configure source sets , etc. All done via dokkaConfiguration DSL. testInline function is the main entry point for unit tests You can pass plugins to be used in a test, notice pluginOverrides parameter You can write asserts for different stages of generating documentation, the main ones being Documentables model generation, Pages generation and Output generation. Since we implemented our plugin to work during PreMergeDocumentableTransformer stage, we can test it on the same level (that is preMergeDocumentablesTransformationStage ). You will need to write asserts using the model of whatever stage you choose. For Documentable transformation stage it's Documentable , for Page generation stage you would have Page model, and for Output you can have .html files that you will need to parse with JSoup (there are also utilities for that). Full source code of this tutorial can be found in Dokka's examples under hide-internal-api .","title":"Unit testing"},{"location":"user_guide/output-formats/html/","text":"","title":"Html"}]}